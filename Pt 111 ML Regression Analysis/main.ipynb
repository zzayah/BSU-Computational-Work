{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One: Graphing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making pandas dataframe\n",
    "original_df = pd.read_csv('data.csv')\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates and visualizes a plot of the x and y coordinates of the values\n",
    "plt.scatter(original_df['X'], original_df['Y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlays visualization of the values of the SCFshift according to magnitude\n",
    "plt.scatter(original_df['X'], original_df['Y'], c=original_df['SCFshift'], cmap='viridis', alpha=0.8)\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot with Gradient')\n",
    "\n",
    "plt.colorbar(label='SCFshift')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two: Polynomial Regresssion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines the correlation between the SCFshift and the other values\n",
    "list = original_df.corr(numeric_only=True).abs()[[\"SCFshift\"]]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new dataframe with the selected columns\n",
    "selected_columns = ['G3-2 R_cut = 8', 'G3-2 R_cut = 9', 'G3-2 R_cut = 7', 'G3-2 R_cut = 10', 'G3-1 R_cut = 7']\n",
    "normalized_df = original_df[selected_columns]\n",
    "\n",
    "# normalizes the values in the new dataframe\n",
    "for column in selected_columns:\n",
    "    min_val = np.min(normalized_df[column])\n",
    "    max_val = np.max(normalized_df[column])\n",
    "    normalized_df[column] = (normalized_df[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "normalized_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Three: Random Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer these questions using clustering, you can perform the following steps:\n",
    "\n",
    "* Select a subset of points from your list randomly or use an initial set of diverse points.  \n",
    "* Apply a clustering algorithm (e.g., k-means, DBSCAN) to cluster these points based on their features.  \n",
    "* Analyze the clusters and select representative points from each cluster.  \n",
    "* Perform DFT calculations for the selected representative points and compute the corresponding adsorption energies.  \n",
    "* Fit a linear regression model using the computed energies and the features of the representative points.  \n",
    "* valuate the model's performance metrics (e.g., RMSE, R-squared) to assess its accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def calculate_clusters(df, n_clusters):\n",
    "    points = df.values\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    labels = kmeans.fit_predict(points)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    return labels, points, centroids, kmeans\n",
    "\n",
    "labels, points, centroids, kmeans = calculate_clusters(normalized_df, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the centroids\n",
    "\n",
    "closest_indices = []\n",
    "\n",
    "# Iterate over each centroid and find the index of the closest point\n",
    "for centroid in centroids:\n",
    "    centroid_distances = [np.linalg.norm(point - centroid) for point in points]\n",
    "    closest_index = np.argmin(centroid_distances)\n",
    "    closest_indices.append(closest_index)\n",
    "\n",
    "closest_indices\n",
    "# Get the corresponding variables of the closest points\n",
    "closest_points = normalized_df.iloc[closest_indices]\n",
    "\n",
    "# Create a Pandas DataFrame with the closest points\n",
    "closest_points_df = pd.DataFrame(closest_points, columns=normalized_df.columns)\n",
    "\n",
    "# Get the corresponding values of the closest SCF\n",
    "closest_scf = original_df.iloc[:, 3].iloc[closest_indices]\n",
    "\n",
    "# Create a Pandas DataFrame with the closest SCF\n",
    "closest_scf_df = closest_scf.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(X_value, y_value, _degree):\n",
    "    # training our model on our cluster centroids and their corresponding SCFshift values\n",
    "    X_train = X_value\n",
    "    y_train = y_value\n",
    "    \n",
    "    X_test = normalized_df[~normalized_df.isin(X_train)].dropna()\n",
    "    y_test = original_df['SCFshift'].to_frame()[~original_df['SCFshift'].to_frame().isin(y_train)].dropna()\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=_degree)\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "    # Create and train the polynomial regression model\n",
    "    poly_regression_model = LinearRegression()\n",
    "    poly_regression_model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Generate predictions for the test dataset\n",
    "    y_pred = poly_regression_model.predict(X_test_poly)\n",
    "\n",
    "    # Calculate reliability score (R-squared)\n",
    "    mean_error = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    return mean_error\n",
    "\n",
    "# Initialize lists to store cluster values and corresponding errors\n",
    "cluster_values = []\n",
    "error_values = []\n",
    "\n",
    "# Iterate over different values of the number of clusters\n",
    "for num_clusters in range(2, 16):\n",
    "    labels, points, centroids, kmeans = calculate_clusters(normalized_df, num_clusters)\n",
    "\n",
    "    # Get the centroids\n",
    "\n",
    "    closest_indices = []\n",
    "\n",
    "# Iterate over each centroid and find the index of the closest point\n",
    "    for centroid in centroids:\n",
    "        centroid_distances = [np.linalg.norm(point - centroid) for point in points]\n",
    "        closest_index = np.argmin(centroid_distances)\n",
    "        closest_indices.append(closest_index)\n",
    "    print(closest_indices)\n",
    "# Get the corresponding variables of the closest points\n",
    "    closest_points = normalized_df.iloc[closest_indices]\n",
    "\n",
    "# Create a Pandas DataFrame with the closest points\n",
    "    closest_points_df = pd.DataFrame(closest_points, columns=normalized_df.columns)\n",
    "\n",
    "# Get the corresponding values of the closest SCF\n",
    "    closest_scf = original_df.iloc[:, 3].iloc[closest_indices]\n",
    "\n",
    "# Create a Pandas DataFrame with the closest SCF\n",
    "    closest_scf_df = closest_scf.to_frame()\n",
    "    # Call the regression model function\n",
    "    error = regression_model(closest_points_df, closest_scf_df, num_clusters)\n",
    "    \n",
    "    # Append the cluster value and error to the respective lists\n",
    "    cluster_values.append(num_clusters)\n",
    "    error_values.append(error)\n",
    "\n",
    "# Plotting the error values\n",
    "plt.plot(cluster_values, error_values)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error vs Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Four: Alternate Alglorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_wcss(centroid, data_points):\n",
    "    distances = np.sum((data_points - centroid) ** 2, axis=1)\n",
    "    wcss = np.sum(distances)\n",
    "    return wcss\n",
    "\n",
    "X_values = normalized_df\n",
    "\n",
    "cluster_accuracy_per_iteration = np.array()\n",
    "\n",
    "for clusterNum in range(0, 14):\n",
    "    cluster_accuracy_per_iteration[clusterNum] = calculate_wcss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One: Graphing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates and visualizes a plot of the x and y coordinates of the values\n",
    "plt.scatter(original_df['X'], original_df['Y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two: Polynomial Regresssion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new dataframe with the selected columns\n",
    "selected_columns = ['G3-2 R_cut = 8', 'G3-2 R_cut = 9', 'G3-2 R_cut = 7', 'G3-2 R_cut = 10', 'G3-1 R_cut = 7']\n",
    "normalized_df = original_df[selected_columns]\n",
    "\n",
    "# normalizes the values in the new dataframe\n",
    "for column in selected_columns:\n",
    "    min_val = np.min(normalized_df[column])\n",
    "    max_val = np.max(normalized_df[column])\n",
    "    normalized_df[column] = (normalized_df[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "normalized_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer these questions using clustering, you can perform the following steps:\n",
    "\n",
    "* Select a subset of points from your list randomly or use an initial set of diverse points.  \n",
    "* Apply a clustering algorithm (e.g., k-means, DBSCAN) to cluster these points based on their features.  \n",
    "* Analyze the clusters and select representative points from each cluster.  \n",
    "* Perform DFT calculations for the selected representative points and compute the corresponding adsorption energies.  \n",
    "* Fit a linear regression model using the computed energies and the features of the representative points.  \n",
    "* valuate the model's performance metrics (e.g., RMSE, R-squared) to assess its accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the centroids\n",
    "\n",
    "closest_indices = []\n",
    "\n",
    "# Iterate over each centroid and find the index of the closest point\n",
    "for centroid in centroids:\n",
    "    centroid_distances = [np.linalg.norm(point - centroid) for point in points]\n",
    "    closest_index = np.argmin(centroid_distances)\n",
    "    closest_indices.append(closest_index)\n",
    "\n",
    "closest_indices\n",
    "# Get the corresponding variables of the closest points\n",
    "closest_points = normalized_df.iloc[closest_indices]\n",
    "\n",
    "# Create a Pandas DataFrame with the closest points\n",
    "closest_points_df = pd.DataFrame(closest_points, columns=normalized_df.columns)\n",
    "\n",
    "# Get the corresponding values of the closest SCF\n",
    "closest_scf = original_df.iloc[:, 3].iloc[closest_indices]\n",
    "\n",
    "# Create a Pandas DataFrame with the closest SCF\n",
    "closest_scf_df = closest_scf.to_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Four: Alternate Alglorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (v3.10.5:f377153967, Jun  6 2022, 12:36:10) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04c0dd1a90273e90ffd20b535a252122077e4f6e72cb7d78e3d723cf48786094"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
